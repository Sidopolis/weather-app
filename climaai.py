# -*- coding: utf-8 -*-
"""ClimaAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CYtpCIQWwdkICkmZqJMFyhdMZsUo14L9
"""

from IPython.display import HTML
import time

# Basic modules
import numpy as np
import pandas as pd

#data visualization
import matplotlib.pyplot as plt
# from mpl_toolkits.mplot3d  import Axes3D
import seaborn as sns


# library from preprocessing Module.
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance

# Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score,  recall_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report,roc_auc_score, roc_curve, auc

# DecisionTree
from sklearn.tree import DecisionTreeClassifier
import sklearn.tree as tree


# Cross Validation
from sklearn.model_selection import cross_validate
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold


# RandomForest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

# Tree Visualisation
from sklearn.tree import export_graphviz
from IPython.display import Image
import graphviz

import warnings
warnings.filterwarnings('ignore')

from google.colab import files
upload = files.upload()

df=pd.read_csv("weather_forecast_data.csv")

df.head()

df.info()

df[df.duplicated()]

df.describe()

extremes=df.groupby("Rain").agg(["min", "max"])
extremes

sns.pairplot(df, hue="Rain", corner=True)

# Counting the number of classes in Rain
rain_df = pd.Categorical(df['Rain'],categories=['rain','no rain'])
fig, ax = plt.subplots(1,2,figsize=(10,5))
# bar plot
ax = sns.countplot(data=df, x="Rain",ax=ax[0])
ax.bar_label(ax.containers[0])
#pie plot
rain_df.value_counts().plot.pie(autopct='%1.1f%%',shadow=True,textprops={'fontsize': 10}, ylabel='')
plt.title('Percentage of classes in  Rain', fontsize=16)
plt.show()

plt.figure(figsize=(8,8))
features = ["Temperature", "Humidity", "Wind_Speed", "Cloud_Cover", "Pressure"]
for i,col in enumerate(features):
    plt.subplot(2,3,i + 1)
    sns.boxplot(y=col, data=df,showmeans=True, meanprops={"marker":"o",
                       "markerfacecolor":"white",
                       "markeredgecolor":"black",
                      "markersize":"10"})
    #plt.ylabel('')

plt.tight_layout()
plt.show()

# Correlation matrix
corr = df.corr(numeric_only=True)

# Create a mask using numpy's triu function
mask = np.triu(np.ones_like(corr, dtype=bool))
# Using a heatmap for better visualization
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f",mask = mask,vmin=-1, vmax=1,)
plt.title('Correlation Matrix for Weather Forecast')
plt.show()

# Convert categorical feature Rain  to numerical

label_encoder = LabelEncoder()
df["Rain"] = label_encoder.fit_transform(df["Rain"])
df.head()

# Get the label mappings from label encoder
integer_mapping = {l: i for i, l in enumerate(label_encoder.classes_)}
print(integer_mapping)

# Define features and target
X = df.drop('Rain', axis=1)  # Feature variables
y = df['Rain']  # Target variable

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train lenght:", X_train.shape)
print("X_test lenght:",X_test.shape)

# Standarize numerical features
# define the scaler
scaler = preprocessing.StandardScaler()

# Select only numerical features for scaling
numerical_features = X_train.select_dtypes(include=np.number).columns
# fit on the training data (numerical features only)
scaler.fit(X_train[numerical_features])

# scale on training dataset (numerical features only)
X_train[numerical_features] = scaler.transform(X_train[numerical_features])
#scale on the test dataset (numerical features only)
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

def plot_log(X_values, train_values, test_values, Xlabel, ylabel, title):
    plt.semilogx(X_values, train_values, X_values, test_values)
    plt.xlabel(Xlabel)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend(("Train", "Test"))
    plt.grid()
    plt.show()

# Standard logistic regression with regularization

# list to record the accuracy
training_accuracy = []
testing_accuracy = []

# list to record the error
training_error = []
testing_error = []

# C Hyperparameter
C_param = np.linspace(0.001, 100, 100)

for C_value in C_param:
    #Logistic Regression
    lr = LogisticRegression(C=C_value,penalty= "l2")
    lr.fit(X_train, y_train)

    #Appending the Accuracy Score
    training_accuracy.append(lr.score(X_train, y_train))
    testing_accuracy.append(lr.score(X_test, y_test))

    #Appending the Error Score
    training_error.append(1-lr.score(X_train, y_train))
    testing_error.append(1-lr.score(X_test, y_test))

# Give the best parameter
best_C = C_param[np.argmax(training_accuracy)]
# Plot accuracy vs C

# Plot accuracy vs C
plot_log(C_param, training_accuracy, testing_accuracy, "C Values", "Accuracy", title=f"Best C in training: {best_C:1g} ({np.max(training_accuracy):.2%})")

# Initialize and train the logistic regression model
# choose the model
LR = LogisticRegression(C=best_C,penalty= "l2")
# fit the model with training sets
LR.fit(X_train, y_train)


# Predicting the values for training  and test set
prediction_y_train = LR.predict(X_train) # predict with the X_train
prediction_y_test = LR.predict(X_test)  # predict with X_test

# Evaluate the model
accuracy_training = accuracy_score(y_train, prediction_y_train)
print(f"Accuracy on training: {accuracy_training:.4f}")

accuracy_test = accuracy_score(y_test, prediction_y_test)
print(f"Accuracy on test: {accuracy_test:.4f}")

# Evaluation of the Regression  Model

# Visualize the confussion matriz
cm_st = confusion_matrix(y_test, prediction_y_test)
disp = ConfusionMatrixDisplay(confusion_matrix=cm_st,
                              display_labels=LR.classes_)
disp.plot()
plt.show()

# Extract TP, TN, FP, FN
tn, fp, fn, tp = cm_st.ravel()

print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")

st_classification = classification_report(y_test, prediction_y_test)
print(st_classification)

# Area under ROC curve
rocauc_st = roc_auc_score(y_test,prediction_y_test)
print(f'Area Under the ROC AUC Curve for Standard Logistic Regression: {rocauc_st:.2f}')

# Evaluation with Cross Validation
from sklearn.model_selection import StratifiedKFold
cross_val = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
scores = cross_val_score(LR, X_train, y_train, scoring='accuracy', cv=cross_val, n_jobs=-1)

for index, score in enumerate(scores):
    print('Iteration {} Accuracy score: {}'.format(index + 1, score))

print('\nMean Accuracy: {}'.format(np.mean(scores)))

LR.intercept_

# Get the coefficients associated to features
pd.DataFrame(data=LR.coef_,columns=X.columns)

# Weighted  logistic regression with regularization

# list to record the accuracy
wt_training_accuracy = []
wt_testing_accuracy = []

# list to record the error
wt_training_error = []
wt_testing_error = []

# C Hyperparameter
C_param = np.linspace(0.001, 100, 100)

for C_value in C_param:
    #Logistic Regression
    lr_wt = LogisticRegression(C=C_value,penalty= "l2", solver="liblinear",random_state=42, class_weight= "balanced" ,max_iter=1000)
    lr_wt.fit(X_train, y_train)

    #Appending the Accuracy Score
    wt_training_accuracy.append(lr_wt.score(X_train, y_train))
    wt_testing_accuracy.append(lr_wt.score(X_test, y_test))

    #Appending the Error Score
    wt_training_error.append(1-lr_wt.score(X_train, y_train))
    wt_testing_error.append(1-lr_wt.score(X_test, y_test))

best_C_wt = C_param[np.argmax(wt_training_accuracy)]

plot_log(C_param, wt_training_accuracy, wt_testing_accuracy, "C Values", "Accuracy", title=f"Best C in training: {best_C:1g} ({np.max(wt_training_accuracy):.2%})")

# Weighted Logistic Regression model
LR_wt = LogisticRegression(C = best_C_wt,penalty= "l2", solver="liblinear",random_state=42, class_weight= "balanced" ,max_iter=1000)
# fit it
LR_wt.fit(X_train,y_train)


# Predicting the values for training and testing sets
prediction_y_train_wt = LR_wt.predict(X_train)
prediction_y_test_wt = LR_wt.predict(X_test)

# Evaluate the model
accuracy_training_wt = accuracy_score(y_train, prediction_y_train_wt)
print(f"Accuracy on training: {accuracy_training_wt:.4f}")

accuracy_test_wt = accuracy_score(y_test, prediction_y_test_wt)
print(f"Accuracy on test: {accuracy_test_wt:.4f}")

#Evaluation of the model

# Confussion matrix
cm_wt = confusion_matrix(y_test, prediction_y_test_wt)
cm_wt
# Visualize the confussion matriz
disp = ConfusionMatrixDisplay(confusion_matrix=cm_wt,
                              display_labels=LR_wt.classes_)
disp.plot()
plt.show()

# Extract TP, TN, FP, FN
tn, fp, fn, tp = cm_wt.ravel()

print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")

wt_classification = classification_report(y_test, prediction_y_test_wt)
print(wt_classification)

# Area under ROC curve
rocauc_wt = roc_auc_score(y_test, prediction_y_test_wt)
print(f'Area Under the ROC AUC Curve for Standard Logistic Regression: {rocauc_wt:.2f}')

# Evaluation with Cross Validation
from sklearn.model_selection import StratifiedKFold
cross_val = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
scores = cross_val_score(LR_wt, X_train, y_train, scoring='accuracy', cv=cross_val, n_jobs=-1)

for index, score in enumerate(scores):
    print('Iteration {} Accuracy score: {}'.format(index + 1, score))

print('\nMean Accuracy weighted : {}'.format(np.mean(scores)))

# Understanding the model
# Coefficients of the weighted LR
coefficient_wt= LR_wt.coef_
intercept_wt= LR_wt.intercept_
coeff_wt= coefficient_wt[0]
print("LR_wt coefficient:", np.round(coeff_wt,2),"\n", "LR_wt intercept:", np.round(intercept_wt,2) )

# Get the coefficients associated to features
pd.DataFrame(data=LR_wt.coef_,columns=X.columns)

# Probability
prob_rain = pd.DataFrame(LR_wt.predict_proba(X_test), columns=['P(y=0|X)', 'P(y=1|X)'])
prob_rain.head()

# Split dataset into training and test
X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.2, random_state=42)

# compute the mean absolute error (MAE) of the model
def get_mae(max_leaf_nodes,X_trainset, X_testset, y_trainset, y_testset ):
    model = DecisionTreeClassifier(criterion="entropy", max_leaf_nodes=max_leaf_nodes, max_depth = 6,random_state=42)
    model.fit(X_trainset, y_trainset)
    preds_val = model.predict(X_testset)
    mae = mean_absolute_error(y_testset, preds_val)
    return(mae)

# compare MAE with differing values of max_leaf_nodes
for max_leaf_nodes in range(2,10,1):
    mae = get_mae(max_leaf_nodes,X_trainset, X_testset, y_trainset, y_testset )
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, mae))

# Create Decision Tree classifier object using entropy
clf = DecisionTreeClassifier(criterion="entropy", max_depth = 6,random_state=42)

# Fit the data
clf = clf.fit(X_trainset, y_trainset)

# Predict the response for test dataset
y_pred_clf = clf.predict(X_testset)

classes = label_encoder.classes_
classes

#plot decision tree
fig, ax = plt.subplots(figsize=(6, 6)) #figsize value changes the size of plot
# Convert class names to strings
class_names_str = [str(name) for name in classes]
tree.plot_tree(clf,filled=True, rounded = True,  class_names = class_names_str, ax=ax,feature_names=['Temperature', 'Humidity', 'Wind_Speed', 'Cloud_Cover', 'Pressure'])
# y.unique().tolist()
plt.title("Decision Tree")
plt.show()

# Evaluation of the classification

clf_classification = classification_report(y_testset, y_pred_clf)
print(clf_classification)

# Area under ROC curve
rocauc_clf = roc_auc_score(y_testset, y_pred_clf)
print(f'Area Under Curve for Weighted Logistic Regression: {rocauc_clf:.2f}')

# perform k-fold CV
scores = cross_val_score(clf, X, y, cv=10)

print('Cross-validation scores:', scores)
print('Average cross-validation score:', scores.mean())

# Specify the model
rf_model = RandomForestClassifier(random_state = 42)

# Fit iowa_model with the training data.
rf_model.fit(X_trainset, y_trainset)

# prediction of the rf model
predictions =rf_model.predict(X_testset)
# Calculate the mean absolute error of your Random Forest model on the validation data
rf_val_mae = mean_absolute_error(y_testset, predictions)

print("Validation MAE for Random Forest Model: {}".format(rf_val_mae))

# Evaluation of the classification

rf_classification = classification_report(y_testset, predictions)
print(rf_classification)

# Area under ROC curve
rocauc_rf = roc_auc_score(y_testset, predictions)
print(f'Area Under Curve for Weighted Logistic Regression: {rocauc_rf:.2f}')

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt


# Pick one of the tree from the forest,
tree_to_plot = rf_model.estimators_[2] # index 2

# Plot the decision tree
fig, ax = plt.subplots(figsize=(25, 10)) #figsize value changes the size of plot

plot_tree(tree_to_plot, feature_names=df.columns.tolist(), filled=True, rounded=True, fontsize=10)
plt.title("Decision Tree from Random Forest")
plt.show()

param_dist = {'n_estimators': randint(5,15),
              'max_depth': randint(1,20)}

# Create a random forest classifier
rf = RandomForestClassifier()

# Use random search to find the best hyperparameters
rand_search = RandomizedSearchCV(rf,
                                 param_distributions = param_dist,
                                 n_iter=5,
                                 cv=5)

# Fit the random search object to the data
rand_search.fit(X_trainset, y_trainset)

# Create a variable for the best model
best_rf = rand_search.best_estimator_

# Print the best hyperparameters
print('Best hyperparameters:',  rand_search.best_params_)

# Generate predictions with the best model
y_pred_set = best_rf.predict(X_testset)

# Create the confusion matrix
cm_rf = confusion_matrix(y_testset, y_pred_set)

ConfusionMatrixDisplay(confusion_matrix=cm_rf).plot();

# Evaluation of the classification

rf_classification = classification_report(y_testset, y_pred_set)
print(rf_classification)

# Area under ROC curve
rocauc_rf = roc_auc_score(y_testset,y_pred_set)
print(f'Area Under Curve for Weighted Logistic Regression: {rocauc_rf:.2f}')

# Create a series containing feature importances from the model and feature names from the training data
feature_importances = pd.Series(best_rf.feature_importances_, index=X_trainset.columns).sort_values(ascending=False)

# Plot a simple bar chart
feature_importances.plot.bar();

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

# Use a copy of the dataframe
df_alert = df.copy()

# Encode the target column
df_alert['Rain'] = LabelEncoder().fit_transform(df_alert['Rain'])

# Define alert levels based on attribute thresholds
def classify_alerts(row):
    alerts = []
    if row['Temperature'] > 40:
        alerts.append('Heatwave')
    if row['Humidity'] > 85 and row['Cloud_Cover'] > 70:
        alerts.append('Rain/Flood Risk')
    if row['Wind_Speed'] > 60:
        alerts.append('Cyclone Warning')
    if row['Cloud_Cover'] > 90:
        alerts.append('Rain Imminent')
    if row['Pressure'] < 990:
        alerts.append('Low Pressure - Cyclone Risk')
    return ', '.join(alerts) if alerts else 'Normal'

# Apply the alert classification
df_alert['Alert'] = df_alert.apply(classify_alerts, axis=1)

# Display some rows with predictions
df_alert[['Temperature', 'Humidity', 'Wind_Speed', 'Cloud_Cover', 'Pressure', 'Alert']].head(10)

# prompt: how better is our algorithm and full process than other ai climate websites i want to compare cause im making a research paper on clima ai

import pandas as pd
# Example of adding a baseline model (always predict majority class)
from sklearn.dummy import DummyClassifier

dummy_clf = DummyClassifier(strategy="most_frequent")
dummy_clf.fit(X_train, y_train)
dummy_predictions = dummy_clf.predict(X_test)
dummy_accuracy = accuracy_score(y_test, dummy_predictions)
print(f"Dummy Classifier Accuracy: {dummy_accuracy}")

# ... (rest of your code)

# Compare all your model results in a table
results_df = pd.DataFrame({
    'Model': ['Logistic Regression', 'Weighted Logistic Regression', 'Decision Tree', 'Random Forest', 'Dummy Classifier'],
    'Accuracy': [accuracy_test, accuracy_test_wt,  accuracy_score(y_testset, y_pred_clf), accuracy_score(y_testset, y_pred_set), dummy_accuracy],
    'AUC': [rocauc_st, rocauc_wt, rocauc_clf, rocauc_rf, roc_auc_score(y_test,dummy_predictions)], # etc
    # Include other metrics, such as F1 score, Precision
})

results_df